{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分离超平面：$w^Tx+b=0$\n",
    "\n",
    "点到直线距离：$r=\\frac{|w^Tx+b|}{||w||_2}$\n",
    "\n",
    "$||w||_2$为2-范数：$||w||_2=\\sqrt[2]{\\sum^m_{i=1}w_i^2}$\n",
    "\n",
    "直线为超平面，样本可表示为：\n",
    "\n",
    "$w^Tx+b\\ \\geq+1$\n",
    "\n",
    "$w^Tx+b\\ \\leq+1$\n",
    "\n",
    "#### margin：\n",
    "\n",
    "**函数间隔**：$label(w^Tx+b)\\ or\\ y_i(w^Tx+b)$\n",
    "\n",
    "**几何间隔**：$r=\\frac{label(w^Tx+b)}{||w||_2}$，当数据被正确分类时，几何间隔就是点到超平面的距离\n",
    "\n",
    "为了求几何间隔最大，SVM基本问题可以转化为求解:($\\frac{r^*}{||w||}$为几何间隔，(${r^*}$为函数间隔)\n",
    "\n",
    "$$\\max\\ \\frac{r^*}{||w||}$$\n",
    "\n",
    "$$(subject\\ to)\\ y_i({w^T}x_i+{b})\\geq {r^*},\\ i=1,2,..,m$$\n",
    "\n",
    "分类点几何间隔最大，同时被正确分类。但这个方程并非凸函数求解，所以要先①将方程转化为凸函数，②用拉格朗日乘子法和KKT条件求解对偶问题。\n",
    "\n",
    "①转化为凸函数：\n",
    "\n",
    "先令${r^*}=1$，方便计算（参照衡量，不影响评价结果）\n",
    "\n",
    "$$\\max\\ \\frac{1}{||w||}$$\n",
    "\n",
    "$$s.t.\\ y_i({w^T}x_i+{b})\\geq {1},\\ i=1,2,..,m$$\n",
    "\n",
    "再将$\\max\\ \\frac{1}{||w||}$转化成$\\min\\ \\frac{1}{2}||w||^2$求解凸函数，1/2是为了求导之后方便计算。\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2$$\n",
    "\n",
    "$$s.t.\\ y_i(w^Tx_i+b)\\geq 1,\\ i=1,2,..,m$$\n",
    "\n",
    "②用拉格朗日乘子法和KKT条件求解最优值：\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2$$\n",
    "\n",
    "$$s.t.\\ -y_i(w^Tx_i+b)+1\\leq 0,\\ i=1,2,..,m$$\n",
    "\n",
    "整合成：\n",
    "\n",
    "$$L(w, b, \\alpha) = \\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$$\n",
    "\n",
    "推导：$\\min\\ f(x)=\\min \\max\\ L(w, b, \\alpha)\\geq \\max \\min\\ L(w, b, \\alpha)$\n",
    "\n",
    "根据KKT条件：\n",
    "\n",
    "$$\\frac{\\partial }{\\partial w}L(w, b, \\alpha)=w-\\sum\\alpha_iy_ix_i=0,\\ w=\\sum\\alpha_iy_ix_i$$\n",
    "\n",
    "$$\\frac{\\partial }{\\partial b}L(w, b, \\alpha)=\\sum\\alpha_iy_i=0$$\n",
    "\n",
    "代入$ L(w, b, \\alpha)$\n",
    "\n",
    "$\\min\\  L(w, b, \\alpha)=\\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\frac{1}{2}w^Tw-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i-b\\sum^m_{i=1}\\alpha_iy_i+\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\frac{1}{2}w^T\\sum\\alpha_iy_ix_i-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i+\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\alpha_iy_iw^Tx_i$\n",
    "\n",
    "$\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)$\n",
    "\n",
    "再把max问题转成min问题：\n",
    "\n",
    "$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$\n",
    "\n",
    "$s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$\n",
    "\n",
    "$ \\alpha_i \\geq 0,i=1,2,...,m$\n",
    "\n",
    "以上为SVM对偶问题的对偶形式\n",
    "\n",
    "-----\n",
    "#### kernel\n",
    "\n",
    "在低维空间计算获得高维空间的计算结果，也就是说计算结果满足高维（满足高维，才能说明高维下线性可分）。\n",
    "\n",
    "#### soft margin & slack variable\n",
    "\n",
    "引入松弛变量$\\xi\\geq0$，对应数据点允许偏离的functional margin 的量。\n",
    "\n",
    "目标函数：\n",
    "\n",
    "$$\\min\\ \\frac{1}{2}||w||^2+C\\sum\\xi_i\\qquad s.t.\\ y_i(w^Tx_i+b)\\geq1-\\xi_i$$ \n",
    "\n",
    "对偶问题：\n",
    "\n",
    "$$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$$\n",
    "\n",
    "$$s.t.\\ C\\geq\\alpha_i \\geq 0,i=1,2,...,m\\quad \\sum^m_{i=1}\\alpha_iy_i=0,$$\n",
    "\n",
    "-----\n",
    "\n",
    "#### Sequential Minimal Optimization\n",
    "\n",
    "首先定义特征到结果的输出函数：$u=w^Tx+b$.\n",
    "\n",
    "因为$w=\\sum\\alpha_iy_ix_i$\n",
    "\n",
    "有$u=\\sum y_i\\alpha_iK(x_i, x)-b$\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "$$\\max \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\sum^m_{j=1}\\alpha_i\\alpha_jy_iy_j<\\phi(x_i)^T,\\phi(x_j)>$$\n",
    "\n",
    "$$s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$$\n",
    "\n",
    "$$ \\alpha_i \\geq 0,i=1,2,...,m$$\n",
    "\n",
    "-----\n",
    "参考资料：\n",
    "\n",
    "[1] :[Lagrange Multiplier and KKT](http://blog.csdn.net/xianlingmao/article/details/7919597)\n",
    "\n",
    "[2] :[推导SVM](https://my.oschina.net/dfsj66011/blog/517766)\n",
    "\n",
    "[3] :[机器学习算法实践-支持向量机(SVM)算法原理](http://pytlab.org/2017/08/15/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA-SVM-%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/)\n",
    "\n",
    "[4] :[Python实现SVM](http://blog.csdn.net/wds2006sdo/article/details/53156589)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "def create_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = [\n",
    "        'sepal length', 'sepal width', 'petal length', 'petal width', 'label'\n",
    "    ]\n",
    "    data = np.array(df.iloc[:100, [0, 1, -1]])\n",
    "    for i in range(len(data)):\n",
    "        if data[i, -1] == 0:\n",
    "            data[i, -1] = -1\n",
    "    # print(data)\n",
    "    return data[:, :2], data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a5e4b614e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAZqklEQVR4nO3df4xdZZ3H8fd3h1k7KjBBxoV2CgUhjULB4siPdENY2N1KrdAQ00BkCUhkIbhicDFiDGpjAhsSVGiWBiGLBLaki7UgS8sSsBFUaqYF2rWViIvambIy1LTIMkgZvvvHvdNO79yZuc+998x5nmc+r6Tp3HOfnn6fc/TL7Tmf81xzd0REJH1/UXYBIiLSHmroIiKZUEMXEcmEGrqISCbU0EVEMqGGLiKSiUMaHWhmHUA/MOjuS2veOwd4GHi5ummtu6+YbH9HHnmkz5s3L6hYEZGZbvPmza+5e0+99xpu6MB1wA7gsAnef7q20U9m3rx59Pf3B/z1IiJiZr+b6L2GLrmYWS/wSeDudhUlIiLt1eg19O8AXwbenWTMWWb2gpmtN7OT6g0ws6vMrN/M+oeGhkJrFRGRSUzZ0M1sKfCqu2+eZNgW4Fh3PxW4A1hXb5C73+Xufe7e19NT9xKQiIg0qZFr6IuAC8xsCTALOMzM7nf3S0cHuPvrY35+zMz+1cyOdPfX2l+yiEhr9u3bx8DAAG+99VbZpUxo1qxZ9Pb20tnZ2fCfmbKhu/uNwI2wP83yz2ObeXX7UcAf3N3N7HQqn/x3B9QuIjJtBgYGOPTQQ5k3bx5mVnY547g7u3fvZmBggOOOO67hPxeScjmImV1d/YtXAZ8GrjGzd4Bh4GLXMo4iEqm33nor2mYOYGZ84AMfIPReY1BDd/eNwMbqz6vGbF8JrAz6m0USse65QW59/EV27RlmdncXNyyez7KFc8ouS1oUazMf1Ux9TX9CF5kJ1j03yI1rtzG8bwSAwT3D3Lh2G4CaukRHj/6LTOLWx1/c38xHDe8b4dbHXyypIsnFhg0bmD9/PieccAK33HJLW/aphi4yiV17hoO2izRiZGSEa6+9lvXr17N9+3ZWr17N9u3bW96vLrmITGJ2dxeDdZr37O6uEqqRsrT7PsovfvELTjjhBI4//ngALr74Yh5++GE+8pGPtFSnPqGLTOKGxfPp6uw4aFtXZwc3LJ5fUkUy3UbvowzuGcY5cB9l3XODTe9zcHCQuXPn7n/d29vL4GDz+xulhi4yiWUL53DzRQuY092FAXO6u7j5ogW6ITqDFHEfpV6qux2pG11yEZnCsoVz1MBnsCLuo/T29rJz5879rwcGBpg9e3bT+xulT+giIpOY6H5JK/dRPv7xj/PrX/+al19+mbfffpsHH3yQCy64oOn9jVJDFxGZRBH3UQ455BBWrlzJ4sWL+fCHP8zy5cs56aS6i9SG7bflPYiIZGz0clu7nxZesmQJS5YsaUeJ+6mhi4hMIZX7KLrkIiKSCTV0EZFMqKGLiGRCDV1EJBNq6CIimVBDl2yse26QRbc8xXFf+U8W3fJUS2ttiBTts5/9LB/84Ac5+eST27ZPNXTJQhELKIkU6fLLL2fDhg1t3acaumRBX0Qhhdq6Br59Mnyju/L71jUt7/Lss8/miCOOaENxB+jBIsmCvohCCrN1DfzoC7Cv+r+lvTsrrwFOWV5eXXXoE7pkoYgFlEQAeHLFgWY+at9wZXtk1NAlC/oiCinM3oGw7SXSJRfJQlELKIlweG/lMku97ZFRQ5dspLKAkiTmvJsOvoYO0NlV2d6CSy65hI0bN/Laa6/R29vLN7/5Ta688sqW9qmGLi1r9xfoikRl9Mbnkysql1kO76008xZviK5evboNxR1MDV1aMpr/Ho0Mjua/ATV1yccpy6NLtNSjm6LSEuW/ReKhhi4tUf5bUuXuZZcwqWbqU0OXlij/LSmaNWsWu3fvjrapuzu7d+9m1qxZQX9O19ClJTcsnn/QNXRQ/lvi19vby8DAAENDQ2WXMqFZs2bR2xsWjVRDl5Yo/y0p6uzs5Ljjjiu7jLZTQ5eWKf8tEoeGG7qZdQD9wKC7L615z4DvAkuAN4HL3X1LOwsVSYEy+VKmkE/o1wE7gMPqvHc+cGL11xnAndXfRWYMZfKlbA2lXMysF/gkcPcEQy4E7vOKZ4FuMzu6TTWKJEGZfClbo7HF7wBfBt6d4P05wNjVawaq2w5iZleZWb+Z9cd8d1mkGcrkS9mmbOhmthR41d03TzaszrZxAU93v8vd+9y9r6enJ6BMkfgpky9la+QT+iLgAjP7LfAgcK6Z3V8zZgCYO+Z1L7CrLRWKJEJrskvZpmzo7n6ju/e6+zzgYuApd7+0ZtgjwGVWcSaw191faX+5IvFatnAON1+0gDndXRgwp7uLmy9aoBuiMm2azqGb2dUA7r4KeIxKZPElKrHFK9pSnUhilMmXMgU1dHffCGys/rxqzHYHrm1nYSJfW7eN1Zt2MuJOhxmXnDGXby1bUHZZItHSk6ISpa+t28b9z/5+/+sR9/2v1dRF6tNqixKl1ZvqfIfjJNtFRA1dIjUywbKmE20XETV0iVSH1Xu0YeLtIqKGLpG65Iy5QdtFRDdFJVKjNz6VchFpnJX1FUx9fX3e399fyt8tIpIqM9vs7n313tMndKnrM9/7OT/9zR/3v170oSN44HNnlVhRebTGuaRC19BlnNpmDvDT3/yRz3zv5yVVVJ7RNc4H9wzjHFjjfN1zg2WXJjKOGrqMU9vMp9qeM61xLilRQxeZhNY4l5SooYtMQmucS0rU0GWcRR86Imh7zrTGuaREDV3GeeBzZ41r3jM15aI1ziUlyqGLiCREOXQJVlT2OmS/yn+LhFFDl3FGs9ejcb3R7DXQUkMN2W9RNYjkTNfQZZyistch+1X+WyScGrqMU1T2OmS/yn+LhFNDl3GKyl6H7Ff5b5FwaugyTlHZ65D9Kv8tEk43RWWc0ZuO7U6YhOy3qBpEcqYcuohIQpRDL0AMGenQGmKoWUSKo4behBgy0qE1xFCziBRLN0WbEENGOrSGGGoWkWKpoTchhox0aA0x1CwixVJDb0IMGenQGmKoWUSKpYbehBgy0qE1xFCziBRLN0WbEENGOrSGGGoWkWIphy4ikpCWcuhmNgv4CfCe6viH3P3rNWPOAR4GXq5uWuvuK1opWtrva+u2sXrTTkbc6TDjkjPm8q1lC1oeG0u+PZY6RMrSyCWXPwPnuvsbZtYJPGNm69392ZpxT7v70vaXKO3wtXXbuP/Z3+9/PeK+/3Vtow4ZG0u+PZY6RMo05U1Rr3ij+rKz+quc6zTStNWbdja8PWRsLPn2WOoQKVNDKRcz6zCz54FXgSfcfVOdYWeZ2Qtmtt7MTppgP1eZWb+Z9Q8NDbVQtoQameBeSb3tIWNjybfHUodImRpq6O4+4u4fBXqB083s5JohW4Bj3f1U4A5g3QT7ucvd+9y9r6enp5W6JVCHWcPbQ8bGkm+PpQ6RMgXl0N19D7AR+ETN9tdHL8u4+2NAp5kd2a4ipXWXnDG34e0hY2PJt8dSh0iZGkm59AD73H2PmXUBfwv8S82Yo4A/uLub2elU/kOxu4iCpTmjNzMbSa6EjI0l3x5LHSJlmjKHbmanAN8HOqg06jXuvsLMrgZw91Vm9nngGuAdYBi43t1/Ntl+lUMXEQnXUg7d3bcCC+tsXzXm55XAylaKTE1RmeeQ/HeR+w6ZX4rHIjlb18CTK2DvABzeC+fdBKcsL7sqiYwe/W9CUZnnkPx3kfsOmV+KxyI5W9fAj74A+6qJnb07K69BTV0OosW5mlBU5jkk/13kvkPml+KxSM6TKw4081H7hivbRcZQQ29CUZnnkPx3kfsOmV+KxyI5ewfCtsuMpYbehKIyzyH57yL3HTK/FI9Fcg7vDdsuM5YaehOKyjyH5L+L3HfI/FI8Fsk57yborPkPZGdXZbvIGLop2oSiMs8h+e8i9x0yvxSPRXJGb3wq5SJT0HroIiIJaSmHLvmIIVsuiVMePmpq6DNEDNlySZzy8NHTTdEZIoZsuSROefjoqaHPEDFkyyVxysNHTw19hoghWy6JUx4+emroM0QM2XJJnPLw0dNN0Rkihmy5JE55+Ogphy4ikpAZnUMvKk8dst9Y1vVWtjwyuWe6c59fiGk6Flk39KLy1CH7jWVdb2XLI5N7pjv3+YWYxmOR9U3RovLUIfuNZV1vZcsjk3umO/f5hZjGY5F1Qy8qTx2y31jW9Va2PDK5Z7pzn1+IaTwWWTf0ovLUIfuNZV1vZcsjk3umO/f5hZjGY5F1Qy8qTx2y31jW9Va2PDK5Z7pzn1+IaTwWWd8ULSpPHbLfWNb1VrY8MrlnunOfX4hpPBbKoYuIJGRG59CLony7SCIevR423ws+AtYBH7sclt7W+n4jzNmroTdB+XaRRDx6PfTfc+C1jxx43UpTjzRnn/VN0aIo3y6SiM33hm1vVKQ5ezX0JijfLpIIHwnb3qhIc/Zq6E1Qvl0kEdYRtr1Rkebs1dCboHy7SCI+dnnY9kZFmrPXTdEmKN8ukojRG5/tTrlEmrNXDl1EJCEt5dDNbBbwE+A91fEPufvXa8YY8F1gCfAmcLm7b2m18HpC89+prQEeki3P/VgUmvMNySYXVUeR84swI902oXPL+VjUaOSSy5+Bc939DTPrBJ4xs/Xu/uyYMecDJ1Z/nQHcWf29rULz36mtAR6SLc/9WBSa8w3JJhdVR5HzizQj3Rahc8v5WNQx5U1Rr3ij+rKz+qv2Os2FwH3Vsc8C3WZ2dHtLDc9/p7YGeEi2PPdjUWjONySbXFQdRc4v0ox0W4TOLedjUUdDKRcz6zCz54FXgSfcfVPNkDnA2K4zUN1Wu5+rzKzfzPqHhoaCiw3Nf6e2BnhItjz3Y1Fozjckm1xUHUXOL9KMdFuEzi3nY1FHQw3d3Ufc/aNAL3C6mZ1cM6Re+HlcF3L3u9y9z937enp6gosNzX+ntgZ4SLY892NRaM43JJtcVB1Fzi/SjHRbhM4t52NRR1AO3d33ABuBT9S8NQCMDUD3ArtaqqyO0Px3amuAh2TLcz8WheZ8Q7LJRdVR5PwizUi3Rejccj4WdUzZ0M2sx8y6qz93AX8L/Kpm2CPAZVZxJrDX3V9pd7HLFs7h5osWMKe7CwPmdHdx80ULJrypFzq+bN9atoBLzzxm/yfyDjMuPfOYuimX3I8FpyyHT90Oh88FrPL7p25vz42spbdB35UHPpFbR+V1vZRLUXUUOb8i91220LnlfCzqmDKHbmanAN8HOqj8B2CNu68ws6sB3H1VNba4kson9zeBK9x90pC5cugiIuFayqG7+1ZgYZ3tq8b87MC1rRQpIiKtyf7R/+QeppHpEfKwSQwPphT5ME1qD07FcD4ilXVDT+5hGpkeIQ+bxPBgSpEP06T24FQM5yNiWa+2mNzDNDI9Qh42ieHBlCIfpkntwakYzkfEsm7oyT1MI9Mj5GGTGB5MKfJhmtQenIrhfEQs64ae3MM0Mj1CHjaJ4cGUIh+mSe3BqRjOR8SybujJPUwj0yPkYZMYHkwp8mGa1B6ciuF8RCzrhp7cwzQyPUIeNonhwZQiH6ZJ7cGpGM5HxPQFFyIiCWnpwSKRGS/kyzBikVrNsWTLY6mjSWroIpMJ+TKMWKRWcyzZ8ljqaEHW19BFWhbyZRixSK3mWLLlsdTRAjV0kcmEfBlGLFKrOZZseSx1tEANXWQyIV+GEYvUao4lWx5LHS1QQxeZTMiXYcQitZpjyZbHUkcL1NBFJhPyZRixSK3mWLLlsdTRAuXQRUQSohy6FCvF7G5RNReV/07xGMu0U0OX1qSY3S2q5qLy3ykeYymFrqFLa1LM7hZVc1H57xSPsZRCDV1ak2J2t6iai8p/p3iMpRRq6NKaFLO7RdVcVP47xWMspVBDl9akmN0tquai8t8pHmMphRq6tCbF7G5RNReV/07xGEsplEMXEUnIZDl0fUKXfGxdA98+Gb7RXfl965rp329RNYg0QDl0yUNRWe2Q/SovLiXTJ3TJQ1FZ7ZD9Ki8uJVNDlzwUldUO2a/y4lIyNXTJQ1FZ7ZD9Ki8uJVNDlzwUldUO2a/y4lIyNXTJQ1FZ7ZD9Ki8uJVMOXUQkIS3l0M1srpn92Mx2mNkvzey6OmPOMbO9ZvZ89Zf+jZm6FPPUyosXT8ctao3k0N8BvuTuW8zsUGCzmT3h7ttrxj3t7kvbX6JMuxTz1MqLF0/HLXpTfkJ391fcfUv15z8BO4A5RRcmJUoxT628ePF03KIXdFPUzOYBC4FNdd4+y8xeMLP1ZnbSBH/+KjPrN7P+oaGh4GJlmqSYp1ZevHg6btFruKGb2fuBHwBfdPfXa97eAhzr7qcCdwDr6u3D3e9y9z537+vp6Wm2Zilainlq5cWLp+MWvYYaupl1UmnmD7j72tr33f11d3+j+vNjQKeZHdnWSmX6pJinVl68eDpu0Wsk5WLAPcAOd6+7sLOZHVUdh5mdXt3v7nYWKtMoxTy18uLF03GL3pQ5dDP7a+BpYBvwbnXzV4FjANx9lZl9HriGSiJmGLje3X822X6VQxcRCTdZDn3K2KK7PwPYFGNWAiubK0+atnVNJWGwd6ByHfO8m2b2p6VHr4fN91a+lNk6Kl/91uq3BYkkROuhp0qZ4IM9ej3033PgtY8ceK2mLjOE1nJJlTLBB9t8b9h2kQypoadKmeCD+UjYdpEMqaGnSpngg1lH2HaRDKmhp0qZ4IN97PKw7SIZUkNPlTLBB1t6G/RdeeATuXVUXuuGqMwgWg9dRCQhLeXQZ5J1zw1y6+MvsmvPMLO7u7hh8XyWLcxoYcncc+u5zy8GOsZRU0OvWvfcIDeu3cbwvkoqYnDPMDeu3QaQR1PPPbee+/xioGMcPV1Dr7r18Rf3N/NRw/tGuPXxF0uqqM1yz63nPr8Y6BhHTw29atee4aDtyck9t577/GKgYxw9NfSq2d1dQduTk3tuPff5xUDHOHpq6FU3LJ5PV+fBD6F0dXZww+L5JVXUZrnn1nOfXwx0jKOnm6JVozc+s025jN60yjWhkPv8YqBjHD3l0EVEEjJZDl2XXERSsHUNfPtk+EZ35feta9LYt0wrXXIRiV2R+W9ly7OiT+gisSsy/61seVbU0EViV2T+W9nyrKihi8SuyPy3suVZUUMXiV2R+W9ly7Oihi4SuyLXvte6+llRDl1EJCHKoYuIzABq6CIimVBDFxHJhBq6iEgm1NBFRDKhhi4ikgk1dBGRTKihi4hkYsqGbmZzzezHZrbDzH5pZtfVGWNmdruZvWRmW83stGLKlZZo3WuRrDWyHvo7wJfcfYuZHQpsNrMn3H37mDHnAydWf50B3Fn9XWKhda9FsjflJ3R3f8Xdt1R//hOwA6j9os0Lgfu84lmg28yObnu10jytey2SvaBr6GY2D1gIbKp5aw6wc8zrAcY3fczsKjPrN7P+oaGhsEqlNVr3WiR7DTd0M3s/8APgi+7+eu3bdf7IuFW/3P0ud+9z976enp6wSqU1WvdaJHsNNXQz66TSzB9w97V1hgwAc8e87gV2tV6etI3WvRbJXiMpFwPuAXa4+20TDHsEuKyadjkT2Ovur7SxTmmV1r0WyV4jKZdFwD8A28zs+eq2rwLHALj7KuAxYAnwEvAmcEX7S5WWnbJcDVwkY1M2dHd/hvrXyMeOceDadhUlIiLh9KSoiEgm1NBFRDKhhi4ikgk1dBGRTKihi4hkQg1dRCQTaugiIpmwSoS8hL/YbAj4XSl/+dSOBF4ru4gCaX7pynluoPk14lh3r7sYVmkNPWZm1u/ufWXXURTNL105zw00v1bpkouISCbU0EVEMqGGXt9dZRdQMM0vXTnPDTS/lugauohIJvQJXUQkE2roIiKZmNEN3cw6zOw5M3u0znvnmNleM3u++iup72ozs9+a2bZq7f113jczu93MXjKzrWZ2Whl1NquB+aV+/rrN7CEz+5WZ7TCzs2reT/38TTW/ZM+fmc0fU/fzZva6mX2xZkwh56+RbyzK2XXADuCwCd5/2t2XTmM97fY37j7RQwznAydWf50B3Fn9PSWTzQ/SPn/fBTa4+6fN7C+B99a8n/r5m2p+kOj5c/cXgY9C5UMjMAj8sGZYIedvxn5CN7Ne4JPA3WXXUpILgfu84lmg28yOLrsoATM7DDibynf54u5vu/uemmHJnr8G55eL84DfuHvtU/GFnL8Z29CB7wBfBt6dZMxZZvaCma03s5Omqa52ceC/zGyzmV1V5/05wM4xrweq21Ix1fwg3fN3PDAE/Fv1kuDdZva+mjEpn79G5gfpnr+xLgZW19leyPmbkQ3dzJYCr7r75kmGbaGyZsKpwB3Aumkprn0WuftpVP5pd62ZnV3zfr3viU0pwzrV/FI+f4cApwF3uvtC4P+Ar9SMSfn8NTK/lM8fANVLSRcA/1Hv7TrbWj5/M7KhA4uAC8zst8CDwLlmdv/YAe7+uru/Uf35MaDTzI6c9kqb5O67qr+/SuX63ek1QwaAuWNe9wK7pqe61k01v8TP3wAw4O6bqq8fotIAa8ekev6mnF/i52/U+cAWd/9DnfcKOX8zsqG7+43u3uvu86j8k+gpd7907BgzO8rMrPrz6VSO1e5pL7YJZvY+Mzt09Gfg74H/rhn2CHBZ9W77mcBed39lmkttSiPzS/n8ufv/AjvNbH5103nA9pphyZ6/RuaX8vkb4xLqX26Bgs7fTE+5HMTMrgZw91XAp4FrzOwdYBi42NN5rPavgB9W//9wCPDv7r6hZn6PAUuAl4A3gStKqrUZjcwv5fMH8E/AA9V/tv8PcEVG5w+mnl/S58/M3gv8HfCPY7YVfv706L+ISCZm5CUXEZEcqaGLiGRCDV1EJBNq6CIimVBDFxHJhBq6iEgm1NBFRDLx/wwrnYIQm6xlAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1], label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1], label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, max_iter=100, kernel='linear'):\n",
    "        self.max_iter = max_iter\n",
    "        self._kernel = kernel\n",
    "\n",
    "    def init_args(self, features, labels):\n",
    "        self.m, self.n = features.shape\n",
    "        self.X = features\n",
    "        self.Y = labels\n",
    "        self.b = 0.0\n",
    "\n",
    "        # 将Ei保存在一个列表里\n",
    "        self.alpha = np.ones(self.m)\n",
    "        self.E = [self._E(i) for i in range(self.m)]\n",
    "        # 松弛变量\n",
    "        self.C = 1.0\n",
    "\n",
    "    def _KKT(self, i):\n",
    "        y_g = self._g(i) * self.Y[i]\n",
    "        if self.alpha[i] == 0:\n",
    "            return y_g >= 1\n",
    "        elif 0 < self.alpha[i] < self.C:\n",
    "            return y_g == 1\n",
    "        else:\n",
    "            return y_g <= 1\n",
    "\n",
    "    # g(x)预测值，输入xi（X[i]）\n",
    "    def _g(self, i):\n",
    "        r = self.b\n",
    "        for j in range(self.m):\n",
    "            r += self.alpha[j] * self.Y[j] * self.kernel(self.X[i], self.X[j])\n",
    "        return r\n",
    "\n",
    "    # 核函数\n",
    "    def kernel(self, x1, x2):\n",
    "        if self._kernel == 'linear':\n",
    "            return sum([x1[k] * x2[k] for k in range(self.n)])\n",
    "        elif self._kernel == 'poly':\n",
    "            return (sum([x1[k] * x2[k] for k in range(self.n)]) + 1)**2\n",
    "\n",
    "        return 0\n",
    "\n",
    "    # E（x）为g(x)对输入x的预测值和y的差\n",
    "    def _E(self, i):\n",
    "        return self._g(i) - self.Y[i]\n",
    "\n",
    "    def _init_alpha(self):\n",
    "        # 外层循环首先遍历所有满足0<a<C的样本点，检验是否满足KKT\n",
    "        index_list = [i for i in range(self.m) if 0 < self.alpha[i] < self.C]\n",
    "        # 否则遍历整个训练集\n",
    "        non_satisfy_list = [i for i in range(self.m) if i not in index_list]\n",
    "        index_list.extend(non_satisfy_list)\n",
    "\n",
    "        for i in index_list:\n",
    "            if self._KKT(i):\n",
    "                continue\n",
    "\n",
    "            E1 = self.E[i]\n",
    "            # 如果E2是+，选择最小的；如果E2是负的，选择最大的\n",
    "            if E1 >= 0:\n",
    "                j = min(range(self.m), key=lambda x: self.E[x])\n",
    "            else:\n",
    "                j = max(range(self.m), key=lambda x: self.E[x])\n",
    "            return i, j\n",
    "\n",
    "    def _compare(self, _alpha, L, H):\n",
    "        if _alpha > H:\n",
    "            return H\n",
    "        elif _alpha < L:\n",
    "            return L\n",
    "        else:\n",
    "            return _alpha\n",
    "\n",
    "    def fit(self, features, labels):\n",
    "        self.init_args(features, labels)\n",
    "\n",
    "        for t in range(self.max_iter):\n",
    "            # train\n",
    "            i1, i2 = self._init_alpha()\n",
    "\n",
    "            # 边界\n",
    "            if self.Y[i1] == self.Y[i2]:\n",
    "                L = max(0, self.alpha[i1] + self.alpha[i2] - self.C)\n",
    "                H = min(self.C, self.alpha[i1] + self.alpha[i2])\n",
    "            else:\n",
    "                L = max(0, self.alpha[i2] - self.alpha[i1])\n",
    "                H = min(self.C, self.C + self.alpha[i2] - self.alpha[i1])\n",
    "\n",
    "            E1 = self.E[i1]\n",
    "            E2 = self.E[i2]\n",
    "            # eta=K11+K22-2K12\n",
    "            eta = self.kernel(self.X[i1], self.X[i1]) + self.kernel(\n",
    "                self.X[i2],\n",
    "                self.X[i2]) - 2 * self.kernel(self.X[i1], self.X[i2])\n",
    "            if eta <= 0:\n",
    "                # print('eta <= 0')\n",
    "                continue\n",
    "\n",
    "            alpha2_new_unc = self.alpha[i2] + self.Y[i2] * (\n",
    "                E1 - E2) / eta  #此处有修改，根据书上应该是E1 - E2，书上130-131页\n",
    "            alpha2_new = self._compare(alpha2_new_unc, L, H)\n",
    "\n",
    "            alpha1_new = self.alpha[i1] + self.Y[i1] * self.Y[i2] * (\n",
    "                self.alpha[i2] - alpha2_new)\n",
    "\n",
    "            b1_new = -E1 - self.Y[i1] * self.kernel(self.X[i1], self.X[i1]) * (\n",
    "                alpha1_new - self.alpha[i1]) - self.Y[i2] * self.kernel(\n",
    "                    self.X[i2],\n",
    "                    self.X[i1]) * (alpha2_new - self.alpha[i2]) + self.b\n",
    "            b2_new = -E2 - self.Y[i1] * self.kernel(self.X[i1], self.X[i2]) * (\n",
    "                alpha1_new - self.alpha[i1]) - self.Y[i2] * self.kernel(\n",
    "                    self.X[i2],\n",
    "                    self.X[i2]) * (alpha2_new - self.alpha[i2]) + self.b\n",
    "\n",
    "            if 0 < alpha1_new < self.C:\n",
    "                b_new = b1_new\n",
    "            elif 0 < alpha2_new < self.C:\n",
    "                b_new = b2_new\n",
    "            else:\n",
    "                # 选择中点\n",
    "                b_new = (b1_new + b2_new) / 2\n",
    "\n",
    "            # 更新参数\n",
    "            self.alpha[i1] = alpha1_new\n",
    "            self.alpha[i2] = alpha2_new\n",
    "            self.b = b_new\n",
    "\n",
    "            self.E[i1] = self._E(i1)\n",
    "            self.E[i2] = self._E(i2)\n",
    "        return 'train done!'\n",
    "\n",
    "    def predict(self, data):\n",
    "        r = self.b\n",
    "        for i in range(self.m):\n",
    "            r += self.alpha[i] * self.Y[i] * self.kernel(data, self.X[i])\n",
    "\n",
    "        return 1 if r > 0 else -1\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            result = self.predict(X_test[i])\n",
    "            if result == y_test[i]:\n",
    "                right_count += 1\n",
    "        return right_count / len(X_test)\n",
    "\n",
    "    def _weight(self):\n",
    "        # linear model\n",
    "        yx = self.Y.reshape(-1, 1) * self.X\n",
    "        self.w = np.dot(yx.T, self.alpha)\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVM(max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train done!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn.svm.SVC\n",
    "\n",
    "*(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False,tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None,random_state=None)*\n",
    "\n",
    "参数：\n",
    "\n",
    "- C：C-SVC的惩罚参数C?默认值是1.0\n",
    "\n",
    "C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。\n",
    "\n",
    "- kernel ：核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ \n",
    "    \n",
    "    – 线性：u'v\n",
    "    \n",
    "    – 多项式：(gamma*u'*v + coef0)^degree\n",
    "\n",
    "    – RBF函数：exp(-gamma|u-v|^2)\n",
    "\n",
    "    – sigmoid：tanh(gamma*u'*v + coef0)\n",
    "\n",
    "\n",
    "- degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。\n",
    "\n",
    "\n",
    "- gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’，则会选择1/n_features\n",
    "\n",
    "\n",
    "- coef0 ：核函数的常数项。对于‘poly’和 ‘sigmoid’有用。\n",
    "\n",
    "\n",
    "- probability ：是否采用概率估计？.默认为False\n",
    "\n",
    "\n",
    "- shrinking ：是否采用shrinking heuristic方法，默认为true\n",
    "\n",
    "\n",
    "- tol ：停止训练的误差值大小，默认为1e-3\n",
    "\n",
    "\n",
    "- cache_size ：核函数cache缓存大小，默认为200\n",
    "\n",
    "\n",
    "- class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)\n",
    "\n",
    "\n",
    "- verbose ：允许冗余输出？\n",
    "\n",
    "\n",
    "- max_iter ：最大迭代次数。-1为无限制。\n",
    "\n",
    "\n",
    "- decision_function_shape ：‘ovo’, ‘ovr’ or None, default=None3\n",
    "\n",
    "\n",
    "- random_state ：数据洗牌时的种子值，int值\n",
    "\n",
    "\n",
    "主要调节的参数有：C、kernel、degree、gamma、coef0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
