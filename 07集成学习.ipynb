{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1．提升方法是将弱学习算法提升为强学习算法的统计学习方法。在分类学习中，提升方法通过反复修改训练数据的权值分布，构建一系列基本分类器（弱分类器），并将这些基本分类器线性组合，构成一个强分类器。代表性的提升方法是AdaBoost算法。\n",
    "\n",
    "AdaBoost模型是弱分类器的线性组合：\n",
    "\n",
    "$$f(x)=\\sum_{m=1}^{M} \\alpha_{m} G_{m}(x)$$\n",
    "\n",
    "2．AdaBoost算法的特点是通过迭代每次学习一个基本分类器。每次迭代中，提高那些被前一轮分类器错误分类数据的权值，而降低那些被正确分类的数据的权值。最后，AdaBoost将基本分类器的线性组合作为强分类器，其中给分类误差率小的基本分类器以大的权值，给分类误差率大的基本分类器以小的权值。\n",
    "\n",
    "3．AdaBoost的训练误差分析表明，AdaBoost的每次迭代可以减少它在训练数据集上的分类误差率，这说明了它作为提升方法的有效性。\n",
    "\n",
    "4．AdaBoost算法的一个解释是该算法实际是前向分步算法的一个实现。在这个方法里，模型是加法模型，损失函数是指数损失，算法是前向分步算法。\n",
    "每一步中极小化损失函数\n",
    "\n",
    "$$\\left(\\beta_{m}, \\gamma_{m}\\right)=\\arg \\min _{\\beta, \\gamma} \\sum_{i=1}^{N} L\\left(y_{i}, f_{m-1}\\left(x_{i}\\right)+\\beta b\\left(x_{i} ; \\gamma\\right)\\right)$$\n",
    "\n",
    "得 到 参 数$\\beta_{m}, \\gamma_{m}$。\n",
    "\n",
    "5．提升树是以分类树或回归树为基本分类器的提升方法。提升树被认为是统计学习中最有效的方法之一。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boost\n",
    "\n",
    "“装袋”（bagging）和“提升”（boost）是构建组合模型的两种最主要的方法，所谓的组合模型是由多个基本模型构成的模型，组合模型的预测效果往往比任意一个基本模型的效果都要好。\n",
    "\n",
    "- 装袋：每个基本模型由从总体样本中随机抽样得到的不同数据集进行训练得到，通过重抽样得到不同训练数据集的过程称为装袋。\n",
    "\n",
    "- 提升：每个基本模型训练时的数据集采用不同权重，针对上一个基本模型分类错误的样本增加权重，使得新的模型重点关注误分类样本\n",
    "\n",
    "### AdaBoost\n",
    "\n",
    "AdaBoost是AdaptiveBoost的缩写，表明该算法是具有适应性的提升算法。\n",
    "\n",
    "算法的步骤如下：\n",
    "\n",
    "1）给每个训练样本（$x_{1},x_{2},….,x_{N}$）分配权重，初始权重$w_{1}$均为1/N。\n",
    "\n",
    "2）针对带有权值的样本进行训练，得到模型$G_m$（初始模型为G1）。\n",
    "\n",
    "3）计算模型$G_m$的误分率$e_m=\\sum_{i=1}^Nw_iI(y_i\\not= G_m(x_i))$\n",
    "\n",
    "4）计算模型$G_m$的系数$\\alpha_m=0.5\\log[(1-e_m)/e_m]$\n",
    "\n",
    "5）根据误分率e和当前权重向量$w_m$更新权重向量$w_{m+1}$。\n",
    "\n",
    "6）计算组合模型$f(x)=\\sum_{m=1}^M\\alpha_mG_m(x_i)$的误分率。\n",
    "\n",
    "7）当组合模型的误分率或迭代次数低于一定阈值，停止迭代；否则，回到步骤2）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "- algorithm：这个参数只有AdaBoostClassifier有。主要原因是scikit-learn实现了两种Adaboost分类算法，SAMME和SAMME.R。两者的主要区别是弱学习器权重的度量，SAMME使用了和我们的原理篇里二元分类Adaboost算法的扩展，即用对样本集分类效果作为弱学习器权重，而SAMME.R使用了对样本集分类的预测概率大小来作为弱学习器权重。由于SAMME.R使用了概率度量的连续值，迭代一般比SAMME快，因此AdaBoostClassifier的默认算法algorithm的值也是SAMME.R。我们一般使用默认的SAMME.R就够了，但是要注意的是使用了SAMME.R， 则弱分类学习器参数base_estimator必须限制使用支持概率预测的分类器。SAMME算法则没有这个限制。\n",
    "\n",
    "\n",
    "- n_estimators： AdaBoostClassifier和AdaBoostRegressor都有，就是我们的弱学习器的最大迭代次数，或者说最大的弱学习器的个数。一般来说n_estimators太小，容易欠拟合，n_estimators太大，又容易过拟合，一般选择一个适中的数值。默认是50。在实际调参的过程中，我们常常将n_estimators和下面介绍的参数learning_rate一起考虑。\n",
    "\n",
    "\n",
    "-  learning_rate:  AdaBoostClassifier和AdaBoostRegressor都有，即每个弱学习器的权重缩减系数ν\n",
    "\n",
    "\n",
    "- base_estimator：AdaBoostClassifier和AdaBoostRegressor都有，即我们的弱分类学习器或者弱回归学习器。理论上可以选择任何一个分类或者回归学习器，不过需要支持样本权重。我们常用的一般是CART决策树或者神经网络MLP。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "def create_data():\n",
    "    iris=load_iris()\n",
    "    df=pd.DataFrame(iris.data,columns=iris.feature_names)\n",
    "    df['label']=iris.target\n",
    "    df.columns={'sepal length','sepal width','petal length','petal width','label'}\n",
    "    data=np.array(df.iloc[:100,[0,1,-1]])\n",
    "    for  i in  range(len(data)):\n",
    "        if data[i,-1]==0:\n",
    "            data[i,-1]=-1\n",
    "    return data[:,:2],data[:,-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=create_data()\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x177c2107358>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:50,0],X[:50,1],label='0')\n",
    "plt.scatter(X[50:,0],X[50:,1],label='1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_estimators=50, learning_rate=1.0):\n",
    "        self.clf_num = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def init_args(self, datasets, labels):\n",
    "\n",
    "        self.X = datasets\n",
    "        self.Y = labels\n",
    "        self.M, self.N = datasets.shape\n",
    "\n",
    "        # 弱分类器数目和集合\n",
    "        self.clf_sets = []\n",
    "\n",
    "        # 初始化weights\n",
    "        self.weights = [1.0 / self.M] * self.M\n",
    "\n",
    "        # G(x)系数 alpha\n",
    "        self.alpha = []\n",
    "\n",
    "    def _G(self, features, labels, weights):\n",
    "        m = len(features)\n",
    "        error = 100000.0  # 无穷大\n",
    "        best_v = 0.0\n",
    "        # 单维features\n",
    "        features_min = min(features)\n",
    "        features_max = max(features)\n",
    "        n_step = (features_max - features_min +\n",
    "                  self.learning_rate) // self.learning_rate\n",
    "        # print('n_step:{}'.format(n_step))\n",
    "        direct, compare_array = None, None\n",
    "        for i in range(1, int(n_step)):\n",
    "            v = features_min + self.learning_rate * i\n",
    "\n",
    "            if v not in features:\n",
    "                # 误分类计算\n",
    "                compare_array_positive = np.array(\n",
    "                    [1 if features[k] > v else -1 for k in range(m)])\n",
    "                weight_error_positive = sum([\n",
    "                    weights[k] for k in range(m)\n",
    "                    if compare_array_positive[k] != labels[k]\n",
    "                ])\n",
    "\n",
    "                compare_array_nagetive = np.array(\n",
    "                    [-1 if features[k] > v else 1 for k in range(m)])\n",
    "                weight_error_nagetive = sum([\n",
    "                    weights[k] for k in range(m)\n",
    "                    if compare_array_nagetive[k] != labels[k]\n",
    "                ])\n",
    "\n",
    "                if weight_error_positive < weight_error_nagetive:\n",
    "                    weight_error = weight_error_positive\n",
    "                    _compare_array = compare_array_positive\n",
    "                    direct = 'positive'\n",
    "                else:\n",
    "                    weight_error = weight_error_nagetive\n",
    "                    _compare_array = compare_array_nagetive\n",
    "                    direct = 'nagetive'\n",
    "\n",
    "                # print('v:{} error:{}'.format(v, weight_error))\n",
    "                if weight_error < error:\n",
    "                    error = weight_error\n",
    "                    compare_array = _compare_array\n",
    "                    best_v = v\n",
    "        return best_v, direct, error, compare_array\n",
    "\n",
    "    # 计算alpha\n",
    "    def _alpha(self, error):\n",
    "        return 0.5 * np.log((1 - error) / error)\n",
    "\n",
    "    # 规范化因子\n",
    "    def _Z(self, weights, a, clf):\n",
    "        return sum([\n",
    "            weights[i] * np.exp(-1 * a * self.Y[i] * clf[i])\n",
    "            for i in range(self.M)\n",
    "        ])\n",
    "\n",
    "    # 权值更新\n",
    "    def _w(self, a, clf, Z):\n",
    "        for i in range(self.M):\n",
    "            self.weights[i] = self.weights[i] * np.exp(\n",
    "                -1 * a * self.Y[i] * clf[i]) / Z\n",
    "\n",
    "    # G(x)的线性组合\n",
    "    def _f(self, alpha, clf_sets):\n",
    "        pass\n",
    "\n",
    "    def G(self, x, v, direct):\n",
    "        if direct == 'positive':\n",
    "            return 1 if x > v else -1\n",
    "        else:\n",
    "            return -1 if x > v else 1\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.init_args(X, y)\n",
    "\n",
    "        for epoch in range(self.clf_num):\n",
    "            best_clf_error, best_v, clf_result = 100000, None, None\n",
    "            # 根据特征维度, 选择误差最小的\n",
    "            for j in range(self.N):\n",
    "                features = self.X[:, j]\n",
    "                # 分类阈值，分类误差，分类结果\n",
    "                v, direct, error, compare_array = self._G(\n",
    "                    features, self.Y, self.weights)\n",
    "\n",
    "                if error < best_clf_error:\n",
    "                    best_clf_error = error\n",
    "                    best_v = v\n",
    "                    final_direct = direct\n",
    "                    clf_result = compare_array\n",
    "                    axis = j\n",
    "\n",
    "                # print('epoch:{}/{} feature:{} error:{} v:{}'.format(epoch, self.clf_num, j, error, best_v))\n",
    "                if best_clf_error == 0:\n",
    "                    break\n",
    "\n",
    "            # 计算G(x)系数a\n",
    "            a = self._alpha(best_clf_error)\n",
    "            self.alpha.append(a)\n",
    "            # 记录分类器\n",
    "            self.clf_sets.append((axis, best_v, final_direct))\n",
    "            # 规范化因子\n",
    "            Z = self._Z(self.weights, a, clf_result)\n",
    "            # 权值更新\n",
    "            self._w(a, clf_result, Z)\n",
    "\n",
    "\n",
    "#             print('classifier:{}/{} error:{:.3f} v:{} direct:{} a:{:.5f}'.format(epoch+1, self.clf_num, error, best_v, final_direct, a))\n",
    "#             print('weight:{}'.format(self.weights))\n",
    "#             print('\\n')\n",
    "\n",
    "    def predict(self, feature):\n",
    "        result = 0.0\n",
    "        for i in range(len(self.clf_sets)):\n",
    "            axis, clf_v, direct = self.clf_sets[i]\n",
    "            f_input = feature[axis]\n",
    "            result += self.alpha[i] * self.G(f_input, clf_v, direct)\n",
    "        # sign\n",
    "        return 1 if result > 0 else -1\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        right_count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            feature = X_test[i]\n",
    "            if self.predict(feature) == y_test[i]:\n",
    "                right_count += 1\n",
    "\n",
    "        return right_count / len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(10).reshape(10, 1)\n",
    "y = np.array([1, 1, 1, -1, -1, -1, 1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoost(n_estimators=3, learning_rate=0.5)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoost(n_estimators=10, learning_rate=0.2)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100次结果\n",
    "result = []\n",
    "for i in range(1, 101):\n",
    "    X, y = create_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    clf = AdaBoost(n_estimators=100, learning_rate=0.2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    r = clf.score(X_test, y_test)\n",
    "    # print('{}/100 score：{}'.format(i, r))\n",
    "    result.append(r)\n",
    "\n",
    "print('average score:{:.3f}%'.format(sum(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, learning_rate=0.5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
